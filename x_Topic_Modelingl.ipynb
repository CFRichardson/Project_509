{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Loading Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from modules import PreProcessing, functions\n",
    "from sqlite3 import connect \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as stopwords\n",
    "\n",
    "# to ensure all changes are reflected \n",
    "# in-case jupyter notebook was already oppened\n",
    "\n",
    "from importlib import reload\n",
    "reload(PreProcessing)\n",
    "reload(functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import spacy.cli\n",
    "# spacy.cli.download(\"en_core_web_md\")\n",
    "\n",
    "import spacy_fastlang\n",
    "\n",
    "import spacy\n",
    "from bertopic import BERTopic"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Section 1 - Create a Suport vector machine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "databse_file = 'database.db'\n",
    "main = connect(databse_file)\n",
    "\n",
    "sql_statement_laod_data = '''\n",
    "SELECT \n",
    "    reviews.id, \n",
    "    reviews.course_name,\n",
    "    reviews.text\n",
    "\n",
    "FROM reviews\n",
    "'''\n",
    "\n",
    "df = pd.read_sql_query(sql_statement_laod_data, main)\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isnull().sum() * 100 / len(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.isnull().sum() * 100 / len(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dfX = df.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# OOOPSIES\n",
    "# df = dfX.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "def text_decoder(string):\n",
    "    '''\n",
    "        The following two lines of code are from Wim Feijen on StackOverFlow\n",
    "\n",
    "        Wim Feijen\n",
    "        March 26, 2021\n",
    "        StackOverFlow: Python encoding/decoding problems\n",
    "        https://stackoverflow.com/questions/27996448/python-encoding-decoding-problems\n",
    "    '''\n",
    "    bytes_string = bytes(string, encoding=\"raw_unicode_escape\")\n",
    "    text = bytes_string.decode(\"utf-8\", \"strict\")\n",
    "    return text\n",
    "\n",
    "def lang_detect(clean_string):\n",
    "    clean_string = nlp(clean_string)\n",
    "    return clean_string._.language\n",
    "\n",
    "def tokens_2_keep(text_column):\n",
    "    tokens = text_column.split()\n",
    "    return [token for token in tokens if re.match('^[a-z0-9]+$', token)]\n",
    "\n",
    "nlp = spacy.load('en_core_web_md', exclude=['tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer'])\n",
    "nlp.add_pipe(\"language_detector\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%%time\n",
    "df['language'] = df['text'].apply(lang_detect)\n",
    "df = df[df['language'] == 'en']\n",
    "df['cleaned_text'] = df['text'].apply(text_decoder)\n",
    "# df.sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df['id'] == 19301]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[df['id'] == 29208]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def token_counter(text):\n",
    "    return len(text.split())\n",
    "\n",
    "df['token_count'] = df['cleaned_text'].apply(token_counter)\n",
    "# df[df['token_count'] == 1].sample(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calculate how many single word documents exists in corpus\n",
    "round(df[df['token_count'] == 1].shape[0] / df.shape[0], 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It looks like we are fine from overfitting to the single word documents/reviews, but to stay safe we will create two different models.  One with single word docs and one without single word docs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text_ =  df.loc[df['id'] == 38359, 'cleaned_text'].to_string(index=False)\n",
    "text_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "view = df.loc[df['id'] == 21,'cleaned_text'].to_string(index=False)\n",
    "view"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df['cleaned_text'] = df['cleaned_text'].str.replace('\\\\n','')\n",
    "text_ =  df.loc[df['id'] == 38359, 'cleaned_text'].to_string(index=False)\n",
    "text_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df[['course_name', 'cleaned_text', 'token_count']]\n",
    "df.sample(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md', exclude=['tagger', 'parser', 'ner', 'attribute_ruler', 'lemmatizer'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# topic_model = BERTopic(embedding_model=nlp, nr_topics='auto')\n",
    "# topics, probs = topic_model.fit_transform(df['cleaned_text'])\n",
    "#\n",
    "# fig = topic_model.visualize_topics()\n",
    "# fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "docs = df.loc[df['token_count'] > 4, 'cleaned_text']\n",
    "topic_model = BERTopic(embedding_model=nlp, nr_topics='auto')\n",
    "topics, probs = topic_model.fit_transform(docs)\n",
    "\n",
    "fig = topic_model.visualize_topics()\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vectorizer_model = CountVectorizer(stop_words=stopwords, ngram_range=(2,3))\n",
    "topic_model.update_topics(docs, vectorizer_model=vectorizer_model)\n",
    "\n",
    "fig = topic_model.visualize_topics()\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
    "topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Further reduce topics\n",
    "# topic_model.reduce_topics(docs, nr_topics=50)\n",
    "fig = topic_model.visualize_topics()\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hierarchical_topics = topic_model.hierarchical_topics(docs)\n",
    "topic_model.visualize_hierarchy(hierarchical_topics=hierarchical_topics)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topic_model.get_topic(10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vectorizer_model = CountVectorizer(stop_words=stopwords, ngram_range=(1, 5))\n",
    "topic_model.update_topics(docs, vectorizer_model=vectorizer_model)\n",
    "\n",
    "fig = topic_model.visualize_topics()\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vectorizer_model = CountVectorizer(stop_words=stopwords, ngram_range=(2, 5))\n",
    "topic_model.update_topics(docs, vectorizer_model=vectorizer_model)\n",
    "\n",
    "fig = topic_model.visualize_topics()\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Further reduce topics\n",
    "topic_model.reduce_topics(docs, nr_topics=50)\n",
    "\n",
    "fig = topic_model.visualize_topics()\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Further reduce topics\n",
    "topic_model.reduce_topics(docs, nr_topics=30)\n",
    "\n",
    "fig = topic_model.visualize_topics()\n",
    "fig.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}